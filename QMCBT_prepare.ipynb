{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19f9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import splitting functions\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8b6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_iris_df(iris_df):\n",
    "    iris_df = iris_df.drop(columns='species_id')\n",
    "    iris_df = iris_df.rename(columns={'species_name': 'species'})\n",
    "    dummy_iris_df = pd.get_dummies(iris_df.species, drop_first=True)\n",
    "    iris_df = pd.concat([iris_df, dummy_iris_df], axis=1)\n",
    "    return iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba01c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_titanic_df(titanic_df):\n",
    "    titanic_df = titanic_df.drop(columns=['passenger_id', 'class', 'deck'])\n",
    "    dummy_df = pd.get_dummies(data=titanic_df['sex'], drop_first=True)\n",
    "    dummy_df2 = pd.get_dummies(data=titanic_df['embark_town'], drop_first=False)\n",
    "    titanic_df = pd.concat([titanic_df, dummy_df, dummy_df2], axis=1)\n",
    "    return titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05cfdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_telco_churn_df(telco_churn_df):\n",
    "    telco_churn_df = telco_churn_df.drop(columns=['payment_type_id', 'contract_type_id', \n",
    "                                              'internet_service_type_id', 'customer_id'])\n",
    "    encoded_df = pd.DataFrame()\n",
    "    encoded_df['male_encoded'] = telco_churn_df.gender.map({'Male': 1, 'Female': 0})\n",
    "    encoded_df['partner_encoded'] = telco_churn_df.partner.map({'Yes': 1, 'No': 0})\n",
    "    encoded_df['dependents_encoded'] = telco_churn_df.dependents.map({'Yes': 1, 'No': 0})\n",
    "    encoded_df['phone_service_encoded'] = telco_churn_df.phone_service.map({'Yes': 1, 'No': 0})\n",
    "    encoded_df['multiple_lines_encoded'] = telco_churn_df.phone_service.map({'Yes': 1, 'No': 0})\n",
    "    encoded_df['online_security_encoded'] = telco_churn_df.phone_service.map({'Yes': 1, 'No': 0})\n",
    "    encoded_df['online_backup_encoded'] = telco_churn_df.phone_service.map({'Yes': 1, 'No': 0})\n",
    "    encoded_df['device_protection_encoded'] = telco_churn_df.phone_service.map({'Yes': 1, 'No': 0})\n",
    "    encoded_df['streaming_tv_encoded'] = telco_churn_df.phone_service.map({'Yes': 1, 'No': 0})\n",
    "    encoded_df['streaming_movies_encoded'] = telco_churn_df.phone_service.map({'Yes': 1, 'No': 0})\n",
    "    encoded_df['paperless_billing_encoded'] = telco_churn_df.paperless_billing.map({'Yes': 1, 'No': 0})\n",
    "    encoded_df['churn_encoded'] = telco_churn_df.churn.map({'Yes': 1, 'No': 0})\n",
    "    encoded_df['tech_support_encoded'] = telco_churn_df.churn.map({'Yes': 1, 'No': 0})\n",
    "    encoded_cols = encoded_df.columns\n",
    "\n",
    "    dummy_df = pd.get_dummies(data=telco_churn_df[['internet_service_type', \n",
    "                                                   'contract_type', \n",
    "                                                   'payment_type'\n",
    "                                                  ]], drop_first=False)\n",
    "    \n",
    "    telco_churn_df = pd.concat([telco_churn_df, encoded_df, dummy_df], axis=1)\n",
    "    \n",
    "    drop_cols = ['gender', 'partner', 'dependents', 'phone_service', 'multiple_lines', \n",
    "             'online_security', 'online_backup', 'device_protection', 'streaming_tv', \n",
    "             'streaming_movies', 'paperless_billing', 'churn', 'internet_service_type', \n",
    "             'contract_type', 'payment_type', 'tech_support']\n",
    "    \n",
    "    telco_churn_df = telco_churn_df.drop(columns = drop_cols)\n",
    "    \n",
    "    return telco_churn_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1de9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df, target):\n",
    "    train, test = train_test_split(df, test_size=.2, random_state=123, stratify = df[target])\n",
    "    train, validate = train_test_split(train, test_size=.25, random_state=123, stratify = train[target])\n",
    "    print('_______________________________________________________________')\n",
    "    print('|                              DF                             |')\n",
    "    print('|-------------------|-------------------|---------------------|')\n",
    "    print('|       Train       |       Validate    |          Test       |')\n",
    "    print('|-------------------|-------------------|-----------|---------|')\n",
    "    print('| x_train | y_train |   x_val  |  y_val |   x_test  |  y_test |')\n",
    "    print('|-------------------------------------------------------------|')\n",
    "    print('')\n",
    "    print('* 1. tree_1 = DecisionTreeClassifier(max_depth = 5)')\n",
    "    print('* 2. tree_1.fit(x_train, y_train)')\n",
    "    print('* 3. predictions = tree_1.predict(x_train)')\n",
    "    print('* 4. pd.crosstab(y_train, predictions)')\n",
    "    print('* 5. val_predictions = tree_1.predict(x_val)')\n",
    "    print('* 6. pd.crosstab(y_val, val_predictions)')\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879973b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
