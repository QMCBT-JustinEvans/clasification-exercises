{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496ced86",
   "metadata": {},
   "source": [
    "# Classification Exercises\n",
    "The end product of these exercise is a jupyter notebook (classification_exercises.ipynb) and a acquire.py file. The notebook will contain all your work as you move through the exercises. The acquire.py file should contain the final functions that acquire the data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44363a2",
   "metadata": {},
   "source": [
    "### 1. Make a new repo called ```classification-exercises``` on both GitHub and within your ```codeup-data-science``` directory. This will be where you do your work for this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6ec40",
   "metadata": {},
   "source": [
    "### 2. Inside of your local ```classification-exercises``` repo, create a file named ```.gitignore``` with the following contents:\n",
    "\n",
    "```\n",
    "env.py\n",
    ".DS_Store\n",
    ".ipynb_checkpoints/\n",
    "__pycache__\n",
    "*.csv\n",
    "```\n",
    "\n",
    "Add and commit your ```.gitignore``` file before moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b66ea12",
   "metadata": {},
   "source": [
    "### 3. Now that you are 100% sure that your ```.gitignore``` file lists ```env.py```, create or copy your ```env.py``` file inside of ```classification-exercises```. Running ```git status``` should show that git is ignoring this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85599c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "180b6aba",
   "metadata": {},
   "source": [
    "### 4. In a jupyter notebook, ```classification_exercises.ipynb```, use a python module (pydata or seaborn datasets) containing datasets as a source from the iris data. Create a pandas dataframe, ```df_iris```, from this data.\n",
    "* print the first 3 rows\n",
    "* print the number of rows and columns (shape)\n",
    "* print the column names\n",
    "* print the data type of each column\n",
    "* print the summary statistics for each of the numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e282fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a80b24f",
   "metadata": {},
   "source": [
    "### 5. Read the data from this google sheet (https://docs.google.com/spreadsheets/d/1Uhtml8KY19LILuZsrDtlsHHDC9wuDGUSe8LTEwvdI5g/edit?usp=sharing) into a dataframe, ```df_google```.\n",
    "* print the first 3 rows\n",
    "* print the number of rows and columns\n",
    "* print the column names\n",
    "* print the data type of each column\n",
    "* print the summary statistics for each of the numeric variables\n",
    "* print the unique values for each of your categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23d26aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d43b177",
   "metadata": {},
   "source": [
    "### 6. Download the previous exercise's file into an excel (File → Download → Microsoft Excel). Read the downloaded file into a dataframe named ```df_excel```.\n",
    "* assign the first 100 rows to a new dataframe, ```df_excel_sample```\n",
    "* print the number of rows of your original dataframe\n",
    "* print the first 5 column names\n",
    "* print the column names that have a data type of ```object```\n",
    "* compute the range for each of the numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e8835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dd8cd1c",
   "metadata": {},
   "source": [
    "## Make a new python module, ```acquire.py``` to hold the following data aquisition functions:\n",
    "\n",
    "### 1. Make a function named ```get_titanic_data``` that returns the titanic data from the codeup data science database as a pandas data frame. Obtain your data from the ```Codeup Data Science Database```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba16af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2014aaae",
   "metadata": {},
   "source": [
    "### 2. Make a function named ```get_iris_data``` that returns the data from the ```iris_db``` on the codeup data science database as a pandas data frame. The returned data frame should include the actual name of the species in addition to the ```species_ids```. Obtain your data from the ```Codeup Data Science Database```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce39dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0006b6fb",
   "metadata": {},
   "source": [
    "### 3. Make a function named ```get_telco_data``` that returns the data from the ```telco_churn``` database in SQL. In your SQL, be sure to join ```contract_types```, ```internet_service_types```, ```payment_types``` tables with the customers table, so that the resulting dataframe contains all the contract, payment, and internet service options. Obtain your data from the ```Codeup Data Science Database```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce6ac12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6b6c3c0",
   "metadata": {},
   "source": [
    "### 4. Once you've got your ```get_titanic_data```, ```get_iris_data```, and ```get_telco_data``` functions written, now it's time to add caching to them. To do this, edit the beginning of the function to check for the local filename of ```telco.csv```, ```titanic.csv```, or ```iris.csv```. If they exist, use the ```.csv``` file. If the file doesn't exist, then produce the SQL and pandas necessary to create a dataframe, then write the dataframe to a ```.csv``` file with the appropriate name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b9fa97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
